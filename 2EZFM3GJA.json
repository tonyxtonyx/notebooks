"{\"20170621-155011_1790753917\":{\"id\":\"20170621-155011_1790753917\",\"text\":\"%spark.pyspark\\n\",\"title\":\"\"},\"20170621-112503_896367416\":{\"id\":\"20170621-112503_896367416\",\"text\":\"%spark.pyspark\\n\\n\\nimport numpy as np\\nfrom bokeh.io import output_notebook, show\\nfrom bokeh.plotting import figure\\n\\noutput_notebook()\\n\\n\",\"title\":\"Initialize bokeh for visualization\"},\"20170621-120800_296677966\":{\"id\":\"20170621-120800_296677966\",\"text\":\"%spark.pyspark\\n\\nfrom pyspark.ml.classification import LogisticRegression\\nfrom pyspark.ml.classification import NaiveBayes\\nfrom pyspark.sql import SparkSession\\nfrom pyspark.sql.functions import udf\\nfrom pyspark.sql.types import DoubleType\\n\\n# Load data\\ndataset = spark.read.format(\\\"libsvm\\\").load(\\\"file:\\/\\/\\/tmp\\/sample_binary_classification_data.txt\\\")\\ndataset = dataset.randomSplit([0.7,0.3])\\ntrainSet, testSet = (dataset[0], dataset[1])\\ntrainSet.cache()\\ntestSet.cache()\\n\\nlr1 = LogisticRegression(maxIter=30, regParam=0.1, elasticNetParam=0.3)\\n\\n# Fit the model\\nlrModel1 = lr1.fit(trainSet)\\nlrTrainingSummary1 = lrModel1.summary\\n\\n# Obtain the objective per iteration\\nobjectiveHistory1 = lrTrainingSummary1.objectiveHistory\\n\\nevaluateSummary = lrModel1.evaluate(testSet)\\nevaluateSummary.areaUnderROC\",\"title\":\"Logistic Regression\"},\"20170621-120503_149885741\":{\"id\":\"20170621-120503_149885741\",\"text\":\"%spark.pyspark\\n\\n\\np = figure()\\np.circle(x, y)\\n\\ny_predict = x * lrModel.coefficients + (lrModel.intercept)\\np.line(x, y_predict, color='red', line_width=3)\\n\\nshow(p)\",\"title\":\"Linear Regression\"},\"20170621-120434_191947265\":{\"id\":\"20170621-120434_191947265\",\"text\":\"%spark.pyspark\\n\\n\\nfrom pyspark.ml.regression import LinearRegression\\nimport pandas as pd\\nfrom pyspark.ml.linalg import DenseVector, Vectors, VectorUDT\\nfrom pyspark.sql.functions import udf\\nfrom pyspark.sql.types import UserDefinedType, StringType\\n\\nto_vector = udf(lambda x: Vectors.dense(x), VectorUDT())\\n\\ndf = pd.DataFrame({'features': x, 'label': y})\\ntraining = spark.createDataFrame(df).withColumn('features', to_vector('features'))\\n\\nlr = LinearRegression(maxIter=50, regParam=0.3, elasticNetParam=0.8, solver='l-bfgs')\\n\\n# Fit the model\\nlrModel = lr.fit(training)\\n\\n# Print the coefficients and intercept for linear regression\\nprint(\\\"Coefficients: %s\\\" % str(lrModel.coefficients))\\nprint(\\\"Intercept: %s\\\" % str(lrModel.intercept))\\n\\n# Summarize the model over the training set and print out some metrics\\ntrainingSummary = lrModel.summary\\nprint(\\\"numIterations: %d\\\" % trainingSummary.totalIterations)\\nprint(\\\"objectiveHistory: %s\\\" % str(trainingSummary.objectiveHistory))\\ntrainingSummary.residuals.show()\\nprint(\\\"RMSE: %f\\\" % trainingSummary.rootMeanSquaredError)\\nprint(\\\"r2: %f\\\" % trainingSummary.r2)\\n\\n\\n\",\"title\":\"Linear Regression\"},\"paragraph_1579424966763_-908073771\":{\"id\":\"paragraph_1579424966763_-908073771\",\"text\":\"%md\\n\\nThis is a tutorial of how to use Spark MLlib in Zeppelin, we have 2 examples in this note:\\n\\n* Linear regression, we generate some random data and use a linear regression to fit this data. We use bokeh here to visualize the data and the fitted model.  Besides training, we also visualize the loss value over iteration.\\n* Logstic regression, we use the official `sample_binary_classification_data` of spark as the training data. Besides training, we also visualize the loss value over iteration.\\n\",\"title\":\"Introduction\"},\"paragraph_1579425300864_833813189\":{\"id\":\"paragraph_1579425300864_833813189\",\"text\":\"%sh\\n\\ncd \\/tmp\\nrm -rf sample_binary_classification_data.txt\\nwget https:\\/\\/github.com\\/apache\\/spark\\/raw\\/master\\/data\\/mllib\\/sample_binary_classification_data.txt\\n\",\"title\":\"Download data for logics regression\"},\"20170621-112549_1048642377\":{\"id\":\"20170621-112549_1048642377\",\"text\":\"%spark.pyspark\\n\\nimport numpy as np\\nfrom bokeh.io import output_notebook, show\\nfrom bokeh.plotting import figure\\n\\n\\nnum = 1000\\nx = np.linspace(0, 10, num)\\ny = 2 * x + np.random.normal(0,4, num)\\n\\np = figure()\\np.circle(x, y)\\nshow(p)\",\"title\":\"Generate Data\"},\"20170621-120529_381271006\":{\"id\":\"20170621-120529_381271006\",\"text\":\"%spark.pyspark\\n\\np = figure()\\np.line(range(len(trainingSummary.objectiveHistory)), trainingSummary.objectiveHistory, color='blue', line_width=3)\\nshow(p)\\n\\n\\n\\n\",\"title\":\"Loss\"},\"20170621-121651_569823333\":{\"id\":\"20170621-121651_569823333\",\"text\":\"%spark.pyspark\\n\\np = figure()\\np.line(x=range(len(objectiveHistory1)), y=objectiveHistory1, color='blue', line_width=2, legend='Loss of LR1')\\nshow(p)\",\"title\":\"Loss\"}}"