{"paragraph_1588148301603_1997345504":{"orderNumber":null,"id":"paragraph_1588148301603_1997345504","text":"%spark\n","title":null},"paragraph_1588572279774_1507831415":{"orderNumber":null,"id":"paragraph_1588572279774_1507831415","text":"%md\n\n# Introduction\n\nThis is a tutorial for using spark [delta lake](https://delta.io/) in Zeppelin. You need to run the following paragraph first to load delta package.\n\n","title":null},"paragraph_1588148133131_1770029903":{"orderNumber":null,"id":"paragraph_1588148133131_1770029903","text":"%spark\n\nval df = spark.read.format(\"delta\").option(\"versionAsOf\", 0).load(\"/tmp/delta-table\")\ndf.show()","title":"Read older versions of data using time travel"},"paragraph_1588148062120_1790808564":{"orderNumber":null,"id":"paragraph_1588148062120_1790808564","text":"%spark\n\nval data = spark.range(5, 10)\ndata.write.format(\"delta\").mode(\"overwrite\").save(\"/tmp/delta-table\")\ndf.show()","title":"Overwrite"},"paragraph_1588147833426_1914590471":{"orderNumber":null,"id":"paragraph_1588147833426_1914590471","text":"%spark\n\nval data = spark.range(0, 5)\ndata.write.format(\"delta\").save(\"/tmp/delta-table\")\n","title":"Create a table"},"paragraph_1588147206215_1200788867":{"orderNumber":null,"id":"paragraph_1588147206215_1200788867","text":"%spark.conf\n\nspark.jars.packages io.delta:delta-core_2.11:0.6.0","title":null},"paragraph_1588147954117_626957150":{"orderNumber":null,"id":"paragraph_1588147954117_626957150","text":"%spark\n\nimport io.delta.tables._\nimport org.apache.spark.sql.functions._\n\nval deltaTable = DeltaTable.forPath(\"/tmp/delta-table\")\n\n// Update every even value by adding 100 to it\ndeltaTable.update(\n  condition = expr(\"id % 2 == 0\"),\n  set = Map(\"id\" -> expr(\"id + 100\")))\n\n// Delete every even value\ndeltaTable.delete(condition = expr(\"id % 2 == 0\"))\n\n// Upsert (merge) new data\nval newData = spark.range(0, 20).toDF\n\ndeltaTable.as(\"oldData\")\n  .merge(\n    newData.as(\"newData\"),\n    \"oldData.id = newData.id\")\n  .whenMatched\n  .update(Map(\"id\" -> col(\"newData.id\")))\n  .whenNotMatched\n  .insert(Map(\"id\" -> col(\"newData.id\")))\n  .execute()\n\ndeltaTable.toDF.show()","title":"Conditional update without overwrite"},"paragraph_1588147853461_1624743216":{"orderNumber":null,"id":"paragraph_1588147853461_1624743216","text":"%spark\n\nval df = spark.read.format(\"delta\").load(\"/tmp/delta-table\")\ndf.show()","title":"Read a table"}}